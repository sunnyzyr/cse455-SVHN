<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="Sunny Zheng" />
        <title>SVHN Classification with CNN</title>
        <link rel="icon" type="image/x-icon" href="assets/numbers.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
		<!-- Highlights for code display -->
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/atom-one-dark.min.css">
    </head>
    <body>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
    	<script>hljs.highlightAll();</script>
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light" id="mainNav">
            <div class="container px-4 px-lg-5">
                <a class="navbar-brand" href="index.html">CSE455 Final Project</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="https://github.com/sunnyzyr/cse455-SVHN">Repository</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="https://colab.research.google.com/drive/1reK9UPq6OIdIxycdDmzrJ7MFgrNM3-D-#scrollTo=-sNQBsQiszKj">Code</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Page Header -->
        <header class="masthead" style="background-image: url('assets/img/streetNum.jpeg')">
            <div class="container position-relative px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <div class="post-heading">
                            <h1>Street Number Classification with CNN</h1>
                            <h2 class="subheading">Using the SVHN dataset</h2>
                            <span class="meta">
                                Group Member: Melody Zhang, Sunny Zheng, Yanfeng Cui
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- Post Content-->
        <article class="mb-4">
            <div class="container">
                        <!-- Problem description & Setup -->
                        <a name="setup"></a>
                        <h1>I. Problem description & Setup</h1>
                        <p>
                            Object recognition and image processing have become one of the hottest topics in machine learning due 
                            to their vast and creative potential applications in the real world. The ability to process visual information 
                            using machine learning algorithms can be very useful, such as measuring the quality of NYC Bike Lanes through street 
                            imagery. The <Strong>Street View House Numbers (SVHN) dataset</Strong> is one of the most popular ones within this field. It has been 
                            used in neural networks created by Google to read house numbers and match them to their geolocations. Our project aimed 
                            to learn and train a model that can accurately identify street numbers.

                            Our project is built upon a tutorial 3 notebook on setting up the project on Colab and connecting image data to PyTorch. 
                            Then use a <Strong>convolution neural net(CNN)</Strong> to train a classifier with transfer learning. Finally deployed modifications 
                            to the functions to increase the accuracy of the model.

                        </p>

                        <p>Video summary of the project:</p>
                        <p>
                          <iframe width="560" height="315"
                          src="https://www.youtube.com/embed/oJmXAdRmDEE" title="YouTube video player"
                          frameborder="0" allow="accelerometer; autoplay; clipboard-write;
                          encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                          </p>

                        <!-- Dataset -->
                        <a name="data"></a>
                        <h1>II. Dataset</h1>
                        <p><Strong>The Street View House Numbers (SVHN) dataset</Strong> is a <Strong>Pythorch</Strong> build-in image classification dataset that contains 
                            over 600k labeled real-world images of house numbers taken from Google Street View. The sequence of numbers in 
                            the images is of bounded length.</p>
                        <ul>
                            <li>train_32x32.mat: 73,257 digits for training
                            </li>
                            <li>test._32x32.mat: 26,032 digits for testing
                            </li>
                            <li>extra_32x32.mat: 531,131 additional, less difficult samples, to use as extra training data
                            </li>
                        </ul>
                        <div class="row justify-content-center">
                            <div class="col-8">
                                <img class="img-fluid" src="assets/img/data-img.png" alt="numbers" />
                                <span class="caption text-muted">Numbers from the Training Dataset</span>
                            </div>
                        </div>

                        <!-- Techniques -->
                        <a name="tech"></a>
                        <h1>III. Techniques & Evaluations</h1>
                        <p>We used transfer learning to create the neural network for classifying images. <Strong>Transfer learning</Strong> allows 
                            us to use pre-trained models directly, as feature extraction preprocessing, and integrated into entirely 
                            new models. We would be able to reuse part of the pre-trained model as a start to build our own model.</p>

                        <!-- Pre -->
                        <a name="pre"></a>
                        <h2>Pre-existing work</h2>
                        <p>PyTorch has a number of models built-in and our model was revised from <a href="https://colab.research.google.com/drive/1EBz4feoaUvz-o_yeMI27LEQBkvrXNc_4?usp=sharing#scrollTo=76z4UJgTR13J">tutorial 3</a>: </p>
                        <ul>
                            <li><code>Darknet Reference Model</code>
                            </li>
                        </ul>
                        
                        <!-- Data Loading -->
                        <a name="app1"></a>
                        <h2>Loading data</h2>
                        <p>We found that image augmentation can add more <Strong>randomness</Strong>!</p>
                        <p><Strong>Normalization:</Strong> We perform a grayscale normalization to reduce the effect of illumination's differences, it makes CNN faster.</p>
                        <p><Strong>Random Crop:</Strong> We randomly take 32x32 crops from 40x40 padded images</p>
                        <p><Strong>Random image flip:</Strong> Starter code randomly flips the image horizontally</p>


                        <!-- Pro -->
                        <a name="pro"></a>
                        <h2>Models we created:</h2>
                        <p><Strong>ComplexCNN:</Strong> 4 convolutional layers with batch normalization, maxpooling, a global average pooling, and a linear layer</p>
                        <p><Strong>Structure:</Strong></p>
                        <ul style="list-style-type:none;">
                            <li>Conv2d(3, 16, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(16)</li>
                            <li>Conv2d(16, 32, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(32)</li>
                            <li>Conv2d(32, 64, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(64)</li>
                            <li>Conv2d(64, 128, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(128)</li>
                            <li>Linear(128, 10)</li>
                        </ul>
                        <p>This model is a modification of the model of pytorch tutorial 3. It has successive 3x3 convolutional layers with maxpooling ending with a global average pooling and fully connected layer.
                            Also, since we are using batch normalization we can turn off the biases in the convolutional layers. <code>nn.BatchNorm2d</code> has biases built in and the mean subtraction would undo any bias from the convolutional layer.</p>
                        <p><Strong>Result:</Strong></p>
                        <p>The accuracy is almost 76.1409%. The loss curve looks standard for these types of models.
                        </p>
                        <div class="row justify-content-center">
                            <div class="col-8">
                                <img class="img-fluid" src="assets/img/loss-one.png" alt="numbers" />
                                <span class="caption text-muted">Losses for the first model</span>
                            </div>
                        </div>
                        <p> We also implement transfer learning with this model. From the result we can see that even though the accuracy has not improved significantly, there is still a gap between pretrained testing and not pretrained testing.</p>
                        <div class="row justify-content-center">
                            <div class="col-8">
                                <img class="img-fluid" src="assets/img/pretrain-loss.png" alt="numbers" />
                                <span class="caption text-muted">Losses with the pretrained weights</span>
                            </div>
                        </div>
                        <p><Strong>RevisedCNN:</Strong> 6 convolutioal layers with batch normalization, maxpooling, Rectified Linear Units activation, 3 linear layers</p>
                        <p>Structure:</p>
                        <ul style="list-style-type:none;">
                            <li>Conv2d(3, 16, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(16)</li>
                            <li>ReLU()</li>
                            <li>Conv2d(16, 32, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(32)</li>
                            <li>ReLU()</li>
                            <li>MaxPool2d(2, 2)</li>
                            <li>Conv2d(32, 64, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(64)</li>
                            <li>ReLU()</li>
                            <li>Conv2d(64, 128, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(128)</li>
                            <li>MaxPool2d(2, 2)</li>
                            <li>Conv2d(128, 256, 3, padding=1, bias=False)</li>
                            <li>BatchNorm2d(256)</li>
                            <li>ReLU()</li>
                            <li>Conv2d(256, 256, 3, padding=1, bias=False)</li>
                            <li>ReLU()</li>
                            <li>MaxPool2d(2, 2)</li>
                            <li>Flatten()</li>
                            <li>Linear(4*4*256, 1024)</li>
                            <li>ReLU()</li>
                            <li>Linear(1024, 512)</li>
                            <li>ReLU()</li>
                            <li>Linear(512, 10)</li>
                        </ul>   
                        <p>We started with adding more layers. We had a couple of additional convolutional layers to extract more features as well as more linear transformation layers and ReLu. Then we wanted to avoid overfitting, so we added a dropout function. We also did a little testing and tuning, trying out different parameters for the functions and changing the learning rate slightly. At the end, the model was able to reach around 93% of accuracy. </p>
                        <div class="row justify-content-center">
                            <div class="col-8">
                                <img class="img-fluid" src="assets/img/loss-two.png" alt="numbers" />
                                <span class="caption text-muted">Losses for the second model</span>
                            </div>
                        </div>
                        <p>Then we also used an open source library, gradio, to create a little GUI for our model. We created a sketch pad that allows users to input handwritten digits, which the model will recognize the input synchronously.</p>
                        <div class="row justify-content-center">
                            <div class="col-8">
                                <img class="img-fluid" src="assets/img/label.png" alt="numbers" />
                                <span class="caption text-muted">Gradio GUI</span>
                            </div>
                        </div>
                        
                        <!-- Takeaways -->
                        <a name="takeaway"></a>
                        <h1>IV. Takeaways</h1>
                        <p>One challenge we have is to picking which model used to train at the beginning since there are lots of models provided by the Pythorch. So there are many other models that we did not get to explore. For the next step, we will try explore using different optimizers for different network architectures. And also try different image augmentation method that get the model to a better accuracy.</p>

                        <!-- References -->
                        <a name="ref"></a>
                        <h1>V. References</h1>
                        <ul>
                            <li>[1] Tutorial 3. <i>ImageNet and Transfer Learning.</i> Colab. Retrieved June 4, 2022, from https://colab.research.google.com/drive/1EBz4feoaUvz-o_yeMI27LEQBkvrXNc_4?usp=sharing#scrollTo=76z4UJgTR13J </li>
                        </ul>
                    </div>
                </div>
            </div>
        </article>
        <!-- Footer-->
        <footer class="border-top">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <ul class="list-inline text-center">
                            <li class="list-inline-item">
                                <a href="https://github.com/sunnyzyr/cse455-SVHN">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                        </ul>
                        <div class="small text-center text-muted fst-italic">Copyright &copy; CSE 455 Final Project</div>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>